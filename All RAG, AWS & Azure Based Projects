## GraphRAG AI – Advanced Retrieval-Augmented Generation with Graph Knowledge

### Overview
This project is an end-to-end Retrieval-Augmented Generation (RAG) platform that enables users to query complex knowledge bases through a web interface. It designs and implements RAG pipelines using LangChain and LangGraph, integrates AWS OpenSearch with KNN plugin for vector storage and retrieval, handles complex query chaining and prompt orchestration, and incorporates graph-based knowledge representations using Neo4j. The solution is containerized with Docker and deployed on AWS ECS for scalability.

### Core Functionalities

#### RAG Pipeline Design & Implementation
- Pipelines built using LangChain for data ingestion, retrieval, and generation.
- LangGraph utilized for orchestrating multi-step workflows and state management in RAG processes.

#### Vector Database Integration
- AWS OpenSearch with KNN plugin for efficient vector similarity search.
- Documents are embedded and indexed into OpenSearch for fast retrieval.

#### Complex Query Handling
- Supports query chaining where multiple retrieval and generation steps are linked.
- Prompt orchestration to dynamically construct and refine prompts based on intermediate results.

#### Graph-Based Knowledge Representations
- Neo4j used to store and query graph-structured data for enhanced context and relationships.
- Integration with RAG to combine vector search with graph traversals for more accurate responses.

#### Web Application
- Flask backend with a simple UI for user queries and displaying responses.
- Session management for multi-turn interactions.

#### Error Handling & Logging
- Centralized logging with Python’s logging module.
- Custom exceptions for pipeline failures and query errors.

#### Deployment & CI/CD
- Dockerized services for easy deployment.
- AWS ECS: RAG API and graph services run as ECS tasks with auto-scaling.
- AWS EC2: For compute-intensive tasks like embedding generation.
- AWS S3: Storage for raw data files.
- Jenkins pipeline: Automated build, test, and deployment.

### Tech Stack
- **Programming Language**: Python 3.11
- **Frameworks**: LangChain, LangGraph, Flask
- **LLM**: OpenAI GPT models (via LangChain integrations)
- **Vector Store**: AWS OpenSearch with KNN plugin
- **Graph Database**: Neo4j
- **Libraries**: langchain, langgraph, neo4j, opensearch-py, huggingface_hub
- **Containerization**: Docker
- **Automation**: Jenkins Pipeline
- **Cloud Deployment**: AWS ECS, AWS EC2, AWS S3
- **Monitoring**: AWS CloudWatch

### Key Highlights
- **Advanced RAG Pipelines**: Leverages LangChain and LangGraph for flexible, stateful RAG workflows.
- **Hybrid Retrieval**: Combines vector search in OpenSearch with graph queries in Neo4j for richer insights.
- **Complex Query Support**: Handles chained queries and orchestrated prompts for sophisticated user interactions.
- **Scalable Deployment**: AWS-based infrastructure ensures high availability and auto-scaling.
- **Robust Architecture**: Modular design with comprehensive logging and CI/CD for maintainability.
